{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/x6850/works/repos/rt_hp\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find any image in the train2017 of which has 2000 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_path = os.getcwd()+'/dataset/annotations/'\n",
    "tData_path = os.getcwd()+'/dataset/train2017/'\n",
    "vData_path = os.getcwd()+'/dataset/valid2017/'\n",
    "trn_filepath = ann_path + 'person_keypoints_train2017.json'\n",
    "val_filepath = ann_path + 'person_keypoints_valid2017.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n2000\n"
     ]
    }
   ],
   "source": [
    "with open(trn_filepath, 'r') as j_obj:\n",
    "    train2017_ann = json.load(j_obj)\n",
    "    \n",
    "print(type(train2017_ann))\n",
    "if type(train2017_ann) is list:\n",
    "    print(len(train2017_ann))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'http://www.sinaimg.cn/dy/slidenews/4_img/2013_47/704_1154733_789201.jpg', 'keypoint_annotations': {'human3': [144, 180, 1, 171, 325, 2, 256, 428, 2, 265, 196, 1, 297, 311, 1, 300, 412, 1, 178, 476, 2, 0, 0, 3, 0, 0, 3, 253, 474, 2, 0, 0, 3, 0, 0, 3, 220, 23, 1, 205, 133, 1], 'human1': [313, 201, 1, 312, 313, 2, 320, 424, 1, 406, 197, 2, 431, 286, 2, 459, 269, 1, 375, 447, 2, 0, 0, 3, 0, 0, 3, 416, 441, 1, 0, 0, 3, 0, 0, 3, 395, 74, 1, 372, 170, 1], 'human2': [637, 374, 2, 626, 509, 1, 0, 0, 3, 755, 347, 1, 728, 538, 1, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0, 3, 604, 169, 1, 674, 290, 1]}, 'image_id': '054d9ce9201beffc76e5ff2169d2af2f027002ca', 'human_annotations': {'human3': [88, 7, 340, 599], 'human1': [279, 55, 492, 599], 'human2': [541, 131, 870, 599]}}\n"
     ]
    }
   ],
   "source": [
    "print(train2017_ann[0])\n",
    "val_ann = train2017_ann[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/x6850/works/repos/rt_hp/dataset/valid2017/054d9ce9201beffc76e5ff2169d2af2f027002ca.jpg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_id = '054d9ce9201beffc76e5ff2169d2af2f027002ca.jpg'\n",
    "img_src = tData_path + img_id\n",
    "img_dst = vData_path + img_id\n",
    "copyfile(img_src, img_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(val_filepath, 'w') as jw_obj:\n",
    "    json.dump([val_ann], jw_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### some infos in the img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of people:  3\n"
     ]
    }
   ],
   "source": [
    "nb_people = len(val_ann['keypoint_annotations'])\n",
    "print('Num of people: ', nb_people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_list = ['RShoulder', 'RElbow', 'RWrist', 'LShoulder', 'LElbow', 'LWrist', 'RHip', 'RKnee', 'RAnkle',\n",
    "           'LHip', 'LKnee', 'LAnkle', 'Head', 'Neck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human3\nRShoulder vis\nRElbow inv\nRWrist inv\nLShoulder vis\nLElbow vis\nLWrist vis\nRHip inv\nRKnee none\nRAnkle none\nLHip inv\nLKnee none\nLAnkle none\nHead vis\nNeck vis\n-------------------------------\nhuman1\nRShoulder vis\nRElbow inv\nRWrist vis\nLShoulder inv\nLElbow inv\nLWrist vis\nRHip inv\nRKnee none\nRAnkle none\nLHip vis\nLKnee none\nLAnkle none\nHead vis\nNeck vis\n-------------------------------\nhuman2\nRShoulder inv\nRElbow vis\nRWrist none\nLShoulder vis\nLElbow vis\nLWrist none\nRHip none\nRKnee none\nRAnkle none\nLHip none\nLKnee none\nLAnkle none\nHead vis\nNeck vis\n-------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key in val_ann['keypoint_annotations'].keys():\n",
    "    print(key)\n",
    "    for j in range(len(kp_list)):\n",
    "        tp = ['_', 'vis', 'inv', 'none']\n",
    "        print(kp_list[j], tp[val_ann['keypoint_annotations'][key][j*3+2]])\n",
    "    print('-------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在工程下建立一个4000trn, 500val的小数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_train_imgpath = '/media/x6850/DataI/Data1/aic/aic_train/train/'\n",
    "aic_train_annos = \\\n",
    "    '/media/x6850/DataI/Data1/aic/aic_train/keypoint_train_annotations_20170909.json'\n",
    "aic_valid_imgpath = '/media/x6850/DataI/Data1/aic/aic_valid/valid/'\n",
    "aic_valid_annos = \\\n",
    "    '/media/x6850/DataI/Data1/aic/aic_valid/keypoint_validation_annotations_20170911.json'\n",
    "\n",
    "temp_train_imgpath = '/home/x6850/works/input/AIC/train/'\n",
    "temp_train_annos = \\\n",
    "    '/home/x6850/works/input/AIC/annotations/train_annotations_temp.json'\n",
    "temp_valid_imgpath = '/home/x6850/works/input/AIC/valid/'\n",
    "temp_valid_annos = \\\n",
    "    '/home/x6850/works/input/AIC/annotations/valid_annotations_temp.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_train_imgs = os.listdir(aic_train_imgpath)\n",
    "origin_valid_imgs = os.listdir(aic_valid_imgpath)\n",
    "\n",
    "with open(aic_train_annos, 'r') as j_obj_0:\n",
    "    origin_train_annos = json.load(j_obj_0)\n",
    "    \n",
    "with open(aic_valid_annos, 'r') as j_obj_1:\n",
    "    origin_valid_annos = json.load(j_obj_1)\n",
    "\n",
    "origin_train_imgs = [i for i in origin_train_imgs if i.split('.')[-1] == 'jpg']\n",
    "origin_valid_imgs = [i for i in origin_valid_imgs if i.split('.')[-1] == 'jpg'] \n",
    "trainset_size = len(origin_train_imgs)\n",
    "validset_size = len(origin_valid_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_size_temp = 4000\n",
    "validset_size_temp = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rand_idx = np.random.permutation(trainset_size)[:trainset_size_temp]\n",
    "valid_rand_idx = np.random.permutation(validset_size)[:validset_size_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_imgfile_temp = [origin_train_imgs[i].split('.')[0] for i in train_rand_idx]\n",
    "val_imgfile_temp = [origin_valid_imgs[i].split('.')[0] for i in valid_rand_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4fefef6ec1f743b60f85f23e68907304a19fdaf4'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_imgfile_temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_imgfile_temp0 = [i for i in trn_imgfile_temp]\n",
    "val_imgfile_temp0 = [i for i in val_imgfile_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_temp_dataset(img_tuple, src_path, dst_path, annos):\n",
    "    img_list_temp = [i for i in img_tuple]\n",
    "    img_anno_temp = []\n",
    "    \n",
    "    for i in annos:\n",
    "        try:\n",
    "            idx = img_list_temp.index(i['image_id'])\n",
    "            img_id = img_list_temp.pop(idx) + '.jpg'\n",
    "            copyfile(src_path+img_id, dst_path+img_id)\n",
    "            \n",
    "            img_anno_temp.append(i)\n",
    "            \n",
    "            if len(img_list_temp) == 0:\n",
    "                break\n",
    "                \n",
    "        except ValueError:\n",
    "            continue\n",
    "            \n",
    "    return img_anno_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_annos = gen_temp_dataset(tuple(trn_imgfile_temp), \n",
    "                             aic_train_imgpath,\n",
    "                             temp_train_imgpath,\n",
    "                             origin_train_annos)\n",
    "\n",
    "val_annos = gen_temp_dataset(tuple(val_imgfile_temp), \n",
    "                             aic_valid_imgpath,\n",
    "                             temp_valid_imgpath,\n",
    "                             origin_valid_annos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(temp_train_annos, 'w') as j_obj3:\n",
    "    json.dump(trn_annos, j_obj3)\n",
    "    \n",
    "with open(temp_valid_annos, 'w') as j_obj4:\n",
    "    json.dump(val_annos, j_obj4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_sample; reload(generate_sample)\n",
    "from generate_sample import check_sample, gen_sample_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The json file contains keypoint infos for 4000 images.\nThe image path contains 4000 images.\nThe numbers match.\nNow check if the ids match...\ncheck passed.\nThe json file contains keypoint infos for 500 images.\nThe image path contains 500 images.\nThe numbers match.\nNow check if the ids match...\ncheck passed.\n"
     ]
    }
   ],
   "source": [
    "check_sample(temp_train_imgpath, temp_train_annos)\n",
    "check_sample(temp_valid_imgpath, temp_valid_annos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sample_dataset(temp_valid_imgpath, temp_valid_annos, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_valid_imgpath = '/home/x6850/works/input/AIC/valid_sample/'\n",
    "sample_valid_annos = \\\n",
    "    '/home/x6850/works/input/AIC/valid_sample_kp.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The json file contains keypoint infos for 5 images.\nThe image path contains 5 images.\nThe numbers match.\nNow check if the ids match...\ncheck passed.\n"
     ]
    }
   ],
   "source": [
    "check_sample(sample_valid_imgpath, sample_valid_annos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
